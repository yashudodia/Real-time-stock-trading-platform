version : '3.8'

services:
  
  flink-jobmanager:
    image: flink:latest # Use an appropriate version
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager

  flink-taskmanager:
    image: flink:latest # Use an appropriate version
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2

  mongodb:
    image: mongo
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data:/data/db
  # zookeeper:
  #   image: confluentinc/cp-zookeeper:7.4.0
  #   hostname: zookeeper
  #   container_name: zookeeper
  #   ports:
  #     - "2181:2181"
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   healthcheck:
  #     test: [ "CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181" ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 5
  # broker:
  #   image: confluentinc/cp-kafka:7.4.0
  #   hostname: broker
  #   container_name: broker
  #   depends_on:
  #     zookeeper:
  #       condition: service_healthy
  #   ports:
  #     - "9092:9092"
  #     - "9101:9101"
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  #     KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #     KAFKA_JMX_PORT: 9101
  #     KAFKA_JMX_HOSTNAME: localhost

  #   healthcheck:
  #     test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

 

  # flink-master:
  #   image: bde2020/flink-master:1.14.5-hadoop3.2
  #   hostname: flink-master
  #   container_name: flink-master
  #   ports:
  #     - "8080:8080"
  #     - "8082:8082"

  # flink-worker:
  #   image: bde2020/flink-worker:1.14.5-hadoop3.2
  #   hostname: flink-worker
  #   container_name: flink-worker
  #   environment:
  #     - FLINK_MASTER_PORT_6123_TCP_ADDR=flink-master
  #   depends_on:
  #     - flink-master

  schema_registry:
    image: confluent/schema-registry
    hostname: schema_registry
    container_name: schema_registry
    depends_on:
      - zookeeper
      - broker
    ports:
      - "8085:8085"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema_registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,OPTIONS'
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8085/subjects" ]
      interval: 30s
      timeout: 10s
      retries: 5
  

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.4.0
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  kafka-connect:
    image: radarbase/kafka-connect-transform-keyvalue
    hostname: kafka-connect
    container_name: kafka-connect
    depends_on:
      - zookeeper
      - broker
      - schema_registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema_registry:8085'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema_registry:8085'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'
    volumes:
      - ./kafka-connect:/etc/kafka-connect/jars
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8083/connector-plugins" ]
      interval: 30s
      timeout: 10s
      retries: 5

networks:
  kafka-net:
    driver: bridge
volumes:
  mongodb-data:
  flink_data:
